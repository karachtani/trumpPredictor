With ema

===================================================
LAG 2
best parameters found: 
{'activation': 'logistic', 'alpha': 0.1, 'batch_size': 'auto', 'epsilon': 1e-08, 'hidden_layer_sizes': (10, 4), 'max_iter': 5000, 'momentum': 0.9, 'solver': 'lbfgs'}
MLPClassifier(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(10, 4), learning_rate='constant',
              learning_rate_init=0.001, max_iter=5000, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,
              validation_fraction=0, verbose=False, warm_start=False)
Classification Report
              precision    recall  f1-score   support

          -1       0.56      0.32      0.41      2013
           1       0.61      0.81      0.69      2641

    accuracy                           0.60      4654
   macro avg       0.58      0.56      0.55      4654
weighted avg       0.59      0.60      0.57      4654

Confusion Matrix
[[ 647 1366]
 [ 513 2128]]
Accuracy:
0.5962612806188226

===================================================
LAG 4
best parameters found: 
{'activation': 'logistic', 'alpha': 0.01, 'batch_size': 'auto', 'epsilon': 1e-08, 'hidden_layer_sizes': (10, 4), 'max_iter': 5000, 'momentum': 0.9, 'solver': 'lbfgs'}
MLPClassifier(activation='logistic', alpha=0.01, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(10, 4), learning_rate='constant',
              learning_rate_init=0.001, max_iter=5000, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,
              validation_fraction=0, verbose=False, warm_start=False)
Classification Report
              precision    recall  f1-score   support

          -1       0.34      0.03      0.06      1815
           1       0.61      0.96      0.74      2839

    accuracy                           0.60      4654
   macro avg       0.48      0.50      0.40      4654
weighted avg       0.50      0.60      0.48      4654

Confusion Matrix
[[  62 1753]
 [ 119 2720]]
Accuracy:
0.5977653631284916
===================================================
LAG 4
('best parameters found: ', {'activation': 'logistic', 'alpha': 0.1, 'batch_size': 'auto', 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'max_iter': 5000, 'momentum': 0.9, 'solver': 'lbfgs'})
MLPClassifier(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(100,), learning_rate='constant',
              learning_rate_init=0.001, max_iter=5000, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,
              validation_fraction=0, verbose=False, warm_start=False)
Classification Report
              precision    recall  f1-score   support

          -1       0.42      0.10      0.17      1815
           1       0.61      0.91      0.73      2839

    accuracy                           0.60      4654
   macro avg       0.52      0.51      0.45      4654
weighted avg       0.54      0.60      0.51      4654

Confusion Matrix
[[ 190 1625]
 [ 258 2581]]
Accuracy:
0.5954018048990116
===================================================
LAG 4
Model Parameters: 
{'activation': 'logistic', 'alpha': 0.1, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_iter': 5000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 1, 'shuffle': True, 'solver': 'lbfgs', 'tol': 0.0001, 'validation_fraction': 0, 'verbose': False, 'warm_start': False}
Classification Report
              precision    recall  f1-score   support

          -1       0.48      0.10      0.16      1815
           1       0.62      0.93      0.74      2839

    accuracy                           0.61      4654
   macro avg       0.55      0.52      0.45      4654
weighted avg       0.56      0.61      0.52      4654

Confusion Matrix
[[ 178 1637]
 [ 193 2646]]
Accuracy:
0.6067898581865062

===================================================
LAG 3
best parameters found: 
{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'epsilon': 1e-08, 'hidden_layer_sizes': (10, 10, 10), 'max_iter': 5000, 'momentum': 0.9, 'solver': 'lbfgs'}
MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(10, 10, 10), learning_rate='constant',
              learning_rate_init=0.001, max_iter=5000, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,
              validation_fraction=0, verbose=False, warm_start=False)
Classification Report
              precision    recall  f1-score   support

          -1       0.54      0.26      0.35      1986
           1       0.60      0.84      0.70      2668

    accuracy                           0.59      4654
   macro avg       0.57      0.55      0.52      4654
weighted avg       0.58      0.59      0.55      4654

Confusion Matrix
[[ 507 1479]
 [ 429 2239]]
Accuracy:
0.5900300816501933
